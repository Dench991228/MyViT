# Vision Transformers

Implementation of [Vision Transformer](https://openreview.net/forum?id=YicbFdNTTy) in PyTorch, a new model to achieve SOTA in vision classification with using transformer style encoders. Associated [blog](https://abhaygupta.dev/blog/vision-transformer) article.

![ViT](./static/model.png)

## Features

Current Support for:

- [x] Vanilla ViT
- [x] Hybrid ViT (with support for BiT-style resnets)
- [x] Hybrid ViT (with support for AxialResNets as backbone)

To Do:

- [ ] Full Axial-ViT
- [ ] Training Script

## Citations

```BibTeX
@inproceedings{
    anonymous2021an,
    title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
    author={Anonymous},
    booktitle={Submitted to International Conference on Learning Representations},
    year={2021},
    url={https://openreview.net/forum?id=YicbFdNTTy},
    note={under review}
}
```
